<!DOCTYPE html>
<!-- saved from url=(0038)https://events.csa.iisc.ac.in/bcl2018/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
	<meta name="description" content="Workshop">
	<meta name="author" content="br">

	<title> Workshop on <br> 
		Neural Systems - Science and Engineering </title>

	<!-- Bootstrap core CSS -->
	<link href="./assets/bootstrap.min.css" rel="stylesheet">
	<!-- Bootstrap theme -->
	<link href="./assets/bootstrap-theme.min.css" rel="stylesheet">
	<!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
	<link href="./assets/ie10-viewport-bug-workaround.css" rel="stylesheet">
	<!-- font -->
  <link href="./assets/css" rel="stylesheet" type="text/css">
  <!-- Custom styles for this template -->
  <link href="./assets/theme.css" rel="stylesheet">

  <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <style type="text/css">
    .showcase {
      text-align: center;
      background-color: white;
    }

    .showcase h2 {
      font-size: 34px;
    }

    .showcase p {
      font-size: 24px;
    }

    .conjunction {
      text-align: center;
      font-size: 16px;
    }
    .iisc-logo {
      height: 64px;
      width: 64px;
    }
    .mynavbar {
      height: 100px;
      background-color: #FFFFFF;
    }
    .center-align-navbar {
      line-height: 64px;
    }

    .photo {
      height: 100px;
      width: 100px;
      /*max-width: 100%;*/
      /*width: 100%;*/
    }

    .cfp {
      margin-top: 20px;
    }

    .closed {
      color: red;
      margin-top: 20px;
      font-size: 16px;
      font-weight: bold;
    }

    .talk {
      font-weight: bold;
      /*font-style: italic;*/
    }

    

  </style>

</head>
<body>

 <!-- Fixed navbar -->
 <nav class="navbar navbar-fixed-top mynavbar">
  <div class="container">
   <div class="navbar-header">

    <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
     <span class="sr-only">Toggle navigation</span>
     <span class="icon-bar"></span>
     <span class="icon-bar"></span>
     <span class="icon-bar"></span>
   </button>
   <a class="navbar-brand" href="#"><img class="iisc-logo" alt="IISc Logo" src="./assets/iisc-logo.jpg"></a>
   <a class="navbar-brand" href="#"><span class="hidden-xs hidden-sm center-align-navbar"> Home </span> </a>
 </div>
 <div id="navbar" class="navbar-collapse collapse">
  <ul class="nav navbar-nav navbar-right">
    <!-- <li><a href="registration.html"> <span class="center-align-navbar"> Registration </span> </a></li> -->
    <li><a href="./assets/schedule.pdf" target="_blank"> <span class="center-align-navbar"> Schedule </span> </a></li>
    <li><a href="#organizers"> <span class="center-align-navbar">  Organizers </span></a></li>
  </ul>
</div><!--/.nav-collapse -->
</div>
</nav>


<div class="container-fluid" role="main">
  <div class="row">
      <!--         <div class="col-md-2">
        <img src="assets/iisc-logo.jpg" class="img-responsive iisc-logo" alt="IISc logo">
      </div> --> 
      <div class="col-md-12">
        <div class="jumbotron showcase">
          <h2><b>Workshop on <br> Neural Systems - Science and Engineering </b></h2>
          <p> <b> January 23 - 25, 2019 </b></p>
          <p> <b> Faculty Hall, Indian Institute of Science, Bangalore</b></p>
          <p> <b> Sponsored by the Pratiksha Trust and Indian Institute of Science</b></p>
        </div>
      </div> 

    </div>

  </div>


  <div class="container">

    <section class="about">
     <div class="row">
      <div class="col-md-12">
        <p style="text-align: justify;">
          Understanding the processes involved in brain functions like audition and vision forms an important and growing area of interdisciplinary research. These approaches and associated techniques have acted as a melting pot for researchers from disparate disciplines to come together and address one of the grandest challenges of the 21st century. The grandness of the challenge and the requirement on diverse forms of expertise has deemed that such endeavors require synergistic interactions among neurobiologists, electrical engineers and computer scientists. Over the past decade or two, neurobiologists have made significant conceptual advances in our understanding of the brain through technical breakthroughs that have yielded unprecedented opportunities to gather large-scale structural and functional data. Learning and understanding theses tools would enable computer scientists and data analysts to develop exceptional tools to address questions in machine learning and signal processing, tools that are not only helpful in emulating brain function, but also are radically transforming many applications in information and communication technologies. This workshop titled "Neural Systems - Science and Engineering" falls under the broader theme of activities in IISc under the banner of <a href="https://brain-computation.iisc.ac.in/">Brain Computation and Learning (BCL) </a>. The current workshop is aimed at creating this useful dialogue between neurobiologists and computer scientists and educating research students of each area with relevant topics of the other.  
        </p>

        <p style="text-align: justify;">
          A prominent goal of this workshop is to promote synergistic interactions among neuroscientists, electrical engineers,  and computer scientists. The workshop would allow young researchers to understand the diverse themes of research and appreciate the close relationships between these apparently distinct themes.   
        </p>

        <p style="text-align: justify;">
          This workshop is funded by a generous endowment from the Pratiksha Trust, which has been significantly promoting fundamental and translational neuroscience research within the country through the establishment of research centres and chair professorships at the Indian Institutes of Science (Bangalore).
        </p>
      </div>
    </div>	
  </section>

  <section>
    <div class="row">
      <div class="col-md-12">
<!--
        <a class="cfp btn btn-info btn-lg" role="button" href="https://events.csa.iisc.ac.in/bcl2018/1bcl_program.pdf">   Program </a> 
-->
        <span class="closed">
           Attendance to the workshop is FREE but only with a registration. <a href="https://docs.google.com/forms/d/e/1FAIpQLSe9qVpbfcA6S-gkcoYHghCfWBTog_whGDwGrT7ZbIbhruadcw/viewform">Click here</a> for registering.
           We have about 150 seats, allotted on first come first serve basis. We urge you register in the Google form to ensure your participation.
         </span>
        <br>
        
      </div>
    </div></section>
<hr>

<section class="visitors">
 <div class="row">
  <div class="col-md-12"> 
    <h3>How to Reach the Venue</h3>
    <p>
        The venue is Faculty Hall (inside IISc Main Building), IISc Bangalore.
      <a href="https://www.google.com/maps/d/u/0/viewer?mid=1gDdRTbIWDIQh2PKGWDVRBugOZI4&amp;hl=en&amp;ll=13.016363582098782%2C77.56617195000001&amp;z=15">Map of IISc and workshop venue </a>. You can click on icons for more information.          </p>
      <p>
        <i> Additional visitor information at the <a href="http://www.iisc.ac.in/about/general-information/how-to-reach-iisc/">IISc website</a> , and <a href="http://math.iisc.ernet.in/~imi/visitorinfo.php">NMI</a></i>
      </p>
    </div>
  </div>
</section>

<hr>


    <section class="program" id="program">
     <div class="row">
      <div class="col-md-12">

       <center> <h3> CONFIRMED SPEAKERS </h3></center> <br>

       <table class="table">

        <tbody>
        <tr>
          <td>
            <div class="row">
              <div class="col-sm-3">
                <img src="./assets/spk_2.png" class="img-responsive photo">
              </div>
              <div class="col-sm-9">
                <a href="https://www.cmu.edu/dietrich/psychology/holtlab/lori-holt/index.html"><b> Lori Holt</b></a> <p> Carnegie Mellon University </p>
                <p class="talk">
                  Understanding how humans interpret the complexity of spoken language
                </p>
                  <p style="text-align: justify;">
Experience deeply shapes how human listeners perceive spoken language. We learn long-term phonetic representations and words that respect the sound structure of our native language and, yet, we maintain enough flexibility to make sense of experience with nonnative accents or speech from imperfect computer synthesis. There are rich behavioral-science literatures that speak to the many ways that experience shapes speech perception. Yet, for the most part, contemporary neurobiological models of spoken language are oriented toward characterization of the system in a stable state. We are just beginning to understand the learning mechanisms involved in supporting successful human speech communication. I will describe how experience shapes speech perception at different time scales - from the influence of a single precursor sound, to distributions of sounds across seconds, to statistical regularities in acoustics experienced across multiple training sessions. 
<br>
In Part I, I will describe current thinking in how human listeners discover functional units in speech like phonemes and words and how this learning fundamentally shapes perception. In Part II, I will describe more dynamic aspects of speech comprehension that depend on very rapid adaptation and learning at short timescales. In general, this research demonstrates that human speech recognition is a flexible, adaptive, experience‐dependent skill that draws upon perceptual, cognitive, motor and linguistic systems. I will argue that human speech communication has much to offer machine listening and speech recognition and that - reciprocally - next-generation approaches to human speech processing will benefit a great deal from closer connection to machine systems.                  </p>
    
                </div>
              <!--  -->
            </div>
          </td>
        </tr>
        <tr>        
          <td>
            <div class="row">
              <div class="col-sm-3">
                <img src="./assets/spk_4.png" class="img-responsive photo">
              </div>
              <div class="col-sm-9">
                <a href="https://engineering.jhu.edu/ece/faculty/elhilali-mounya/"><b> Mounya Elhilali </b></a> <p> Johns Hopkins University </p>
                <p class="talk">
                   Reverse-engineering auditory computations in the brain
                </p>
                  <p style="text-align: justify;">
                  The perceptual organization of sounds in the environment into coherent objects is a feat constantly facing the auditory system. It manifests itself in the everyday challenge to humans and animals alike to parse complex acoustic information arising from multiple sound sources into separate auditory streams. While seemingly effortless, uncovering the neural mechanisms and computational principles underlying this remarkable ability remain a challenge facing both brain sciences and engineering systems. The perceptual organization of sounds in the environment into coherent objects is a feat constantly facing the auditory system. It manifests itself in the everyday challenge to humans and animals alike to parse complex acoustic information arising from multiple sound sources into separate auditory streams. While seemingly effortless, uncovering the neural mechanisms and computational principles underlying this remarkable ability remain a challenge facing both brain sciences and engineering systems.
                      
                    In the first part of this talk, I review perceptual and neural underpinnings of processing complex soundscapes in the brain and discuss theoretical interpretations of biological processes in an effort to develop more robust sound processing technologies. In the second part of the talk, I will focus on the adaptive capabilities of the auditory system mediated by processes of attention and memory in order to facilitate the perceptual mapping of our acoustic surround. The ability of the auditory system to adapt based on goals and context holds important lessons for developing truly intelligent audio processing system.
                  </p>
              </div>
              <!--  -->
            </div>
          </td>
        </tr>

        <tr>
          <td>
            <div class="row">
              <div class="col-sm-3">
                <img src="./assets/spk_9.png" class="img-responsive photo">
              </div>
              <div class="col-sm-9">
                <a href="https://engineering.wustl.edu/Profiles/Pages/Shantanu-Chakrabartty.aspx"><b>  Shantanu Chakrabartty  </b></a> <p> Washington University St. Louis </p>
                <p class="talk">
                  TBD
                    </p>
                  <p style="text-align: justify;">
                  </p>
                  
              </div>
              <!--  -->
            </div>
          </td>
        </tr>
            
        <tr>    
          <td>
            <div class="row">

              <div class="col-sm-3">
                <img src="./assets/spk_3.png" class="img-responsive photo">
              </div>
              <div class="col-sm-9">
                <a href="https://www.cmu.edu/bme/People/Faculty/profile/bshinncunningham.html"><b> Barbara Shinn-Cunningham</b></a> <p> Carnegie Mellon University</p>
                <p class="talk">
                  Role of attention mechanisms in listening 
                </p>
                  <p style="text-align: justify;">
                    Understanding speech in natural environments depends not just on decoding the speech signal, but on extracting the speech signal from a mixture of sounds. In order to achieve this, the listener must be able to 1) parse the scene, determining what sound energy belongs to the speech signal and what energy is from a competing source (perform auditory scene analysis), and 2) filter out the competing source energy and focus on the speech. Together, these processes allow a listener to focus attention on the speech and analyze its content in detail. In Part I of my presentation, I will illustrate these issues, including what acoustic features support auditory scene analysis and what features allow a listener to focus attention. In Part II, I will describe the different brain networks that control auditory attention, and how we measure the effects of attention on neural processing.                  </p>
              </div>

            </div>
          </td>
        </tr>

        <tr>
          <td>
            <div class="row">
              <div class="col-sm-3">
                <img src="./assets/spk_1.png" class="img-responsive photo">
              </div>
              <div class="col-sm-9">
                <a href="https://www.westernsydney.edu.au/marcs/our_team/research_students/ying_xu"><b> Ying Xu </b></a> <p> Western Sydney University</p>
                <p class="talk">
                  A Digital Neuromorphic Auditory Pathway
                </p>
                  <p style="text-align: justify;">
                    This talk gives an overview of my work on the development of a digital binaural cochlear system, and its applications to a “where” pathway and a “what” pathway model. The binaural cochlear system models the basilar membrane, the outer hair cells, the inner hair cells and the spiral ganglion cells. The “where” pathway model uses a deep convolutional neural network to analyse correlograms from the binaural cochlear system to obtain sound source location. The “what” pathway model uses an event-based unsupervised feature extraction approach to investigate the acoustic characteristics embedded in auditory spike streams from the binaural cochlear system.                  </p>
              </div>

              <!--  -->
            </div>
          </td>
        </tr>
        <tr>
          <td>
            <div class="row">
              <div class="col-sm-3">
                <img src="./assets/spk_5.png" class="img-responsive photo">
              </div>
              <div class="col-sm-9">
                <a href="https://neerajww.github.io/"><b> Neeraj Sharma </b></a> <p> Carnegie Mellon University</p>
                <p class="talk">
                  Talker Change Detection: Humans, Machines, and the Gap
                </p>
                  <p style="text-align: justify;">
                    Studies on natural selection suggest - it is not the strongest of the species that survives, but rather, the one most adaptable to change. A similar strategy might be in play while listening to multi-talker 
                    conversation, composed of multiple talkers speaking in turns. On the listener’s side, the perception of conversational speech demands quick perception and adaptation to talker changes to support communication. The mechanism in play is open for research, and understanding it will benefit design of automatic systems for the flagship problem of conversational speech analysis. In this talk, I will present a study examining human talker change detection (TCD) in multi-party speech utterances using a behavioral paradigm in which listeners indicate the moment of perceived talker change. Modeling the behavioral data shows that the human reaction time can be well estimated using the distance between acoustic features before and after change instant. Further, the estimation improves by incorporation of longer durations of speech prior to talker change. A performance comparison of humans with few of the state-of-the-art machine TCD systems indicates a gap yet to be filled in by machines.                  </p>
              </div>
              <!--  -->
            </div>
          </td>
        </tr>

       <tr>
          <td>
            <div class="row">
              <div class="col-sm-3">
                <img src="./assets/spk_6.png" class="img-responsive photo">
              </div>
              <div class="col-sm-9">
                <a href="http://pnsil.dese.iisc.ac.in/people/"><b> Shayan Garani Srinivasa </b></a> <p> Indian Institute of Science</p>
                <p class="talk">
                  TBD
                </p>
                  <p style="text-align: justify;">
                  </p>
              </div>

              <!--  -->
            </div>
          </td>
        </tr>
        <tr>
          <td>
            <div class="row">
              <div class="col-sm-3">
                <img src="./assets/spk_8.png" class="img-responsive photo">
              </div>
              <div class="col-sm-9">
                <a href="https://isr.umd.edu/faculty/shamma"><b> Shihab Shamma </b></a> <p> University of Maryland</p>
                <p class="talk">
                  TBD
                </p>
                  <p style="text-align: justify;">
                  </p>
              </div>
              <!--  -->
            </div>
          </td>
        </tr>

       <tr>
          <td>
            <div class="row">
              <div class="col-sm-3">
                <img src="./assets/spk_7.png" class="img-responsive photo">
              </div>
              <div class="col-sm-9">
                <a href="https://sites.google.com/site/visionlabiisc/people/sparun"><b> S. P. Arun </b></a> <p> Indian Institute of Science</p>
                <p class="talk">
                  TBD
                </p>
                     <p style="text-align: justify;">
                  </p>
           </div>

              <!--  -->
            </div>
          </td>
        </tr>

</tbody></table>
</div>
</div>	
</section>
<hr>

<!--   <section class="visitors">
</section> -->

<section class="organizers" id="organizers">
 <div class="row">
  <div class="col-md-12">
   <h3> Organizing Committee</h3>

   <ul>
    <li>
      <a href="http://www.leap.ee.iisc.ac.in/sriram/"><b> Sriram Ganapathy</b></a>, IISc
    </li>

   
  <li><a href="http://neuronics.dese.iisc.ac.in/people/"><b> Chetan Singh Thakur</b> </a>, IISc </li>

    <li>
     <a href="http://www.ee.iisc.ac.in/people/faculty/prasantg/"> <b> Prasanta Kumar Ghosh </b></a>, IISc
   </li>
	    <li>
     <a href="https://neerajww.github.io/"> <b> Neeraj Sharma </b></a>, IISc
   </li>
	    <li>
     <a href="http://lcm.csa.iisc.ernet.in/hari/"> <b> Y. Narahari </b></a>, IISc
   </li>
</ul>

</div>
</div>	
</section>

<!-- <section>
  <div class="row">
    <div class="col-md-12">
      <h3> Sponsors</h3>
      <ul>
        <li> <b> Pratiksha Trust, Bangalore </b></li>
        <li> <b> Indian Institute of Science, Bangalore </b></li>
      </ul>
    </div>
  </div>

</section> -->
<br>

<section>
  <div class="row">
    <div class="col-md-12">
      <p> <b>For queries, please write to: <a href="mailto:bcl20xx@gmail.com"> bcl20xx@gmail.com </a> </b></p>
    </div>
  </div>        
</section>

<!--  -->
</div>    


</body></html>
